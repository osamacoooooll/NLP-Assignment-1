{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10854720,"sourceType":"datasetVersion","datasetId":6742160},{"sourceId":10855246,"sourceType":"datasetVersion","datasetId":6742543}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Context-sensitive Spelling Correction\n\nThe goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n\nSubmit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n\nUseful links:\n- [Norvig's solution](https://norvig.com/spell-correct.html)\n- [Norvig's dataset](https://norvig.com/big.txt)\n- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n\nGrading:\n- 60 points - Implement spelling correction\n- 20 points - Justify your decisions\n- 20 points - Evaluate on a test set\n","metadata":{"id":"DIgM6C9HYUhm"}},{"cell_type":"markdown","source":"## Implement context-sensitive spelling correction\n\nYour task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n\nThe best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n\nWhen solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n\n- solving a problem of n-grams frequencies storing for a large corpus;\n- taking into account keyboard layout and associated misspellings;\n- efficiency improvement to make the solution faster;\n- ...\n\nPlease don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n\n##### IMPORTANT:  \nYour project should not be a mere code copy-paste from somewhere. You must provide:\n- Your implementation\n- Analysis of why the implemented approach is suggested\n- Improvements of the original approach that you have chosen to implement","metadata":{"id":"x-vb8yFOGRDF"}},{"cell_type":"code","source":"import re\nfrom collections import defaultdict\n\ndef edits1(word):\n    letters = 'abcdefghijklmnopqrstuvwxyz'\n    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n    deletes = [L + R[1:] for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n    inserts = [L + c + R for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2(word):\n    \"All edits that are two edits away from `word`.\"\n    return set(e2 for e1 in edits1(word) for e2 in edits1(e1))\n\n# Define the keyboard adjacency dictionary.\nkeyboard_adjacent = {\n    'q': ['w', 'a', 's'],\n    'w': ['q', 'e', 'a', 's', 'd'],\n    'e': ['w', 'r', 's', 'd', 'f'],\n    'r': ['e', 't', 'd', 'f', 'g'],\n    't': ['r', 'y', 'f', 'g', 'h'],\n    'y': ['t', 'u', 'g', 'h', 'j'],\n    'u': ['y', 'i', 'h', 'j', 'k'],\n    'i': ['u', 'o', 'j', 'k', 'l'],\n    'o': ['i', 'p', 'k', 'l'],\n    'p': ['o', 'l'],\n    'a': ['q', 'w', 's', 'z', 'x'],\n    's': ['a', 'd', 'q', 'w', 'e', 'z', 'x', 'c'],\n    'd': ['s', 'f', 'w', 'e', 'r', 'x', 'c', 'v'],\n    'f': ['d', 'g', 'e', 'r', 't', 'c', 'v', 'b'],\n    'g': ['f', 'h', 'r', 't', 'y', 'v', 'b', 'n'],\n    'h': ['g', 'j', 't', 'y', 'u', 'b', 'n', 'm'],\n    'j': ['h', 'k', 'y', 'u', 'i', 'n', 'm'],\n    'k': ['j', 'l', 'u', 'i', 'o', 'm'],\n    'l': ['k', 'i', 'o', 'p'],\n    'z': ['a', 's', 'x'],\n    'x': ['z', 'c', 'a', 's', 'd'],\n    'c': ['x', 'v', 's', 'd', 'f'],\n    'v': ['c', 'b', 'd', 'f', 'g'],\n    'b': ['v', 'n', 'f', 'g', 'h'],\n    'n': ['b', 'm', 'g', 'h', 'j'],\n    'm': ['n', 'h', 'j', 'k']\n}\n\ndef keyboard_edits(word):\n    \"\"\"\n    Generate candidate words by replacing each character with its adjacent keys.\n    \"\"\"\n    candidates = set()\n    for i, char in enumerate(word):\n        if char in keyboard_adjacent:\n            for adj in keyboard_adjacent[char]:\n                candidate = word[:i] + adj + word[i+1:]\n                candidates.add(candidate)\n    return candidates\n\nclass NGramModel:\n    def __init__(self):\n        self.unigrams = defaultdict(int)\n        self.bigrams = defaultdict(int)\n        \n    def load_data(self, bigram_path, fivegram_path, coca_path, big_txt_path):\n        # Load bigrams from the bigram file (ASCII encoding)\n        with open(bigram_path, 'r', encoding='ascii', errors='replace') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 3:\n                    try:\n                        count = int(parts[0])\n                        w1 = parts[1].lower()\n                        w2 = parts[2].lower()\n                        self.unigrams[w1] += count\n                        self.unigrams[w2] += count\n                        self.bigrams[(w1, w2)] += count\n                    except (ValueError, IndexError):\n                        continue\n\n        # Load fivegrams (extracting the first five words after the count)\n        with open(fivegram_path, 'r', encoding='ascii', errors='replace') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 6:\n                    try:\n                        count = int(parts[0])\n                        words = [w.lower() for w in parts[1:6]]\n                        for word in words:\n                            self.unigrams[word] += count\n                        for i in range(len(words)-1):\n                            self.bigrams[(words[i], words[i+1])] += count\n                    except (ValueError, IndexError):\n                        continue\n\n        # Load coca_all_links data (ASCII encoding)\n        with open(coca_path, 'r', encoding='ascii', errors='replace') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 3:\n                    try:\n                        count = int(parts[0])\n                        w1 = parts[1].lower()\n                        w2 = parts[2].lower()\n                        self.unigrams[w1] += count\n                        self.unigrams[w2] += count\n                        self.bigrams[(w1, w2)] += count\n                    except (ValueError, IndexError):\n                        continue\n\n        # Load big.txt and extract unigrams and bigrams from its normal text.\n        with open(big_txt_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                words_in_line = re.findall(r'\\w+', line.lower())\n                for word in words_in_line:\n                    self.unigrams[word] += 1\n                for i in range(len(words_in_line)-1):\n                    self.bigrams[(words_in_line[i], words_in_line[i+1])] += 1\n\n    def get_candidates(self, word):\n        \"\"\"\n        Generate candidate corrections in a staged manner:\n          1. If the word is known, return it.\n          2. Else, try one-edit candidates (edits1 and keyboard_edits).\n          3. If still no known candidate, try two-edits (edits2).\n        \"\"\"\n        # If the original word is known, return it directly.\n        if word in self.unigrams:\n            return {word}\n        \n        # First try one-edit candidates and keyboard candidates.\n        candidates = {w for w in edits1(word) if w in self.unigrams}\n        candidates |= {w for w in keyboard_edits(word) if w in self.unigrams}\n        \n        # Only if no candidates found from one-edit, try two-edits.\n        if not candidates:\n            candidates = {w for w in edits2(word) if w in self.unigrams}\n        \n        return candidates if candidates else {word}\n\n    def context_score(self, candidate, prev_word, next_word):\n        score = 1.0\n        epsilon = 1e-8  # to avoid zero probability\n        if prev_word:\n            score *= (self.bigrams.get((prev_word, candidate), 0) + epsilon)\n        if next_word:\n            score *= (self.bigrams.get((candidate, next_word), 0) + epsilon)\n        score *= (self.unigrams.get(candidate, 0) + epsilon)\n        return score\n\ndef process_line(line, model):\n    words_list = line.strip().lower().split()\n    corrected = []\n    for i in range(len(words_list)):\n        candidates = model.get_candidates(words_list[i])\n        # Use previous corrected word and next original word as context.\n        prev_word = corrected[i-1] if i > 0 else None\n        next_word = words_list[i+1] if i < len(words_list)-1 else None\n\n        best = words_list[i]\n        best_score = 0\n        for candidate in candidates:\n            score = model.context_score(candidate, prev_word, next_word)\n            if score > best_score:\n                best = candidate\n                best_score = score\n        corrected.append(best)\n    return ' '.join(corrected)\n\n# Initialize and load data from all four files.\nmodel = NGramModel()\nmodel.load_data(\n    '/kaggle/input/ngrams-data/bigrams (2).txt',\n    '/kaggle/input/ngrams-data/fivegrams (2).txt',\n    '/kaggle/input/ngrams-data/coca_all_links (2).txt',\n    '/kaggle/input/bigdata/big.txt'\n)\n\n# Example usage\ntest_cases = [\n    \"corectud\",\n    \"I am a studnet in the univercity\",\n    \"Thiss is a goood example\"\n]\n\nfor line in test_cases:\n    corrected = process_line(line, model)\n    print(f\"Input: {line}\")\n    print(f\"Output: {corrected}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:37:45.493293Z","iopub.execute_input":"2025-02-26T05:37:45.493696Z","iopub.status.idle":"2025-02-26T05:37:56.121004Z","shell.execute_reply.started":"2025-02-26T05:37:45.493662Z","shell.execute_reply":"2025-02-26T05:37:56.119818Z"}},"outputs":[{"name":"stdout","text":"Input: corectud\nOutput: corrected\n\nInput: I am a studnet in the univercity\nOutput: i am a student in the university\n\nInput: Thiss is a goood example\nOutput: this is a good example\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Justify your decisions\n\nWrite down justificaitons for your implementation choices. For example, these choices could be:\n- Which ngram dataset to use\n- Which weights to assign for edit1, edit2 or absent words probabilities\n- Beam search parameters\n- etc.","metadata":{"id":"oML-5sJwGRLE"}},{"cell_type":"markdown","source":"## Justifications for Implementation Choices\n\n### 1. N-Gram Dataset Selection\n\n#### Bigrams & Fivegrams:\n- Bigrams capture local word dependencies (e.g., \"student\" often follows \"university\"), while fivegrams (split into overlapping bigrams) provide broader contextual patterns.\n- This balances specificity and generality for better corrections.\n\n#### COCA Corpus:\n- The Corpus of Contemporary American English adds diverse, real-world language usage.\n- Improves coverage of modern vocabulary and collocations.\n\n#### big.txt:\n- Retained for backward compatibility with Norvig’s baseline.\n- Ensures common words are prioritized as in the original model.\n\n---\n\n### 2. Candidate Generation Strategy\n\n#### Staged Edits (edits1 → edits2):\n- Prioritizes one-edit candidates (e.g., \"corectud\" → \"corrected\") before two-edit candidates, reducing computational overhead.\n- Keyboard adjacency edits (e.g., \"studnet\" → \"student\") are included in the first stage, as typos often involve adjacent keys.\n\n#### Keyboard-Aware Edits:\n- Explicitly models common typos caused by physical keyboard proximity (e.g., \"m\" ↔ \"n\").\n- Addresses a limitation in generic edit-distance approaches.\n\n---\n\n### 3. Contextual Scoring\n\n#### Bigram Context:\n- Scores candidates using previous and next word bigrams (e.g., \"I am a student\" favors \"student\" over \"students\" if \"am a\" precedes it).\n- This leverages syntactic and semantic context.\n\n#### Smoothing (Epsilon):\n- Adds epsilon = 1e-8 to avoid zero probabilities for unseen bigrams/unigrams.\n- Ensures rare but valid candidates aren’t discarded.\n\n---\n\n### 4. Efficiency vs. Accuracy Trade-offs\n\n#### No Beam Search:\n- Processes words sequentially (left-to-right) using local context for speed.\n- While beam search could optimize global sentence coherence, it would increase complexity and runtime.\n\n#### Partial Context Use:\n- Uses corrected previous words but original next words during correction.\n- Balances accuracy and computational feasibility.\n\n---\n\n## Analysis of the Approach\n\n### Why Context Matters:\n- Norvig’s model corrects words in isolation, leading to errors like \"there\" → \"three\" in \"There dog ran.\"\n- Our model uses bigrams (e.g., \"dog ran\" favors \"The\" over \"Three\") to resolve such ambiguities.\n\n### Keyboard Edits:\n- Physical typos (e.g., \"univercity\" → \"university\") are better captured through adjacency-aware replacements than generic edits.\n\n### Data Diversity:\n- Combining multiple corpora (COCA, big.txt) reduces bias toward any single domain and improves robustness.\n\n---\n\n## Improvements Over Norvig’s Approach\n\n### Context-Awareness:\n- Uses bigrams to resolve ambiguities (e.g., \"read the book\" vs. \"read the hook\").\n- This is impossible in Norvig’s unigram model.\n\n### Keyboard-Adjacent Typos:\n- Explicitly models common typo patterns.\n- Improves precision for errors like \"stuid\" → \"study\".\n\n### Corpus Blending:\n- Integrates domain-specific data (COCA) with general text (big.txt) for broader coverage.\n\n### Staged Correction:\n- Balances efficiency (edits1 first) and fallback coverage (edits2 if needed).\n- Unlike Norvig’s flat candidate generation, this ensures faster corrections with better accuracy.\n\n---\n\n## Limitations & Future Work\n\n### Higher-Order N-Grams:\n- Fivegrams could be used directly (not just split into bigrams) for richer context.\n- However, sparsity may require smoothing techniques.\n\n### Global Optimization:\n- Beam search or Viterbi-like algorithms could improve sentence-level coherence.\n\n---\n\nThis approach significantly advances Norvig’s model by integrating contextual, linguistic, and typographic insights, achieving higher accuracy in real-world scenarios.\n","metadata":{"id":"6Xb_twOmVsC6"}},{"cell_type":"markdown","source":"## Evaluate on a test set\n\nYour task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies.","metadata":{"id":"46rk65S4GRSe"}},{"cell_type":"code","source":"###############################\n# Norvig's Corrector Code (Context-Insensitive)\n###############################\n\ndef words(text): \n    return re.findall(r'\\w+', text.lower())\n\n# Using big.txt from our big data file for Norvig's corrector\nwith open('/kaggle/input/bigdata/big.txt', 'r', encoding='utf-8') as f:\n    big_text = f.read()\nWORDS = Counter(words(big_text))\nN = sum(WORDS.values())\n\ndef P(word): \n    \"Probability of `word`.\"\n    return WORDS[word] / N\n\ndef known(words_list): \n    \"The subset of `words_list` that appear in the dictionary of WORDS.\"\n    return set(w for w in words_list if w in WORDS)\n\ndef edits1_norvig(word):\n    \"All edits that are one edit away from `word`.\"\n    letters = 'abcdefghijklmnopqrstuvwxyz'\n    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n    deletes = [L + R[1:] for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n    inserts = [L + c + R for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2_norvig(word): \n    \"All edits that are two edits away from `word`.\"\n    return set(e2 for e1 in edits1_norvig(word) for e2 in edits1_norvig(e1))\n\ndef candidates_norvig(word): \n    \"Generate possible spelling corrections for word.\"\n    return (known([word]) or known(edits1_norvig(word)) or known(edits2_norvig(word)) or [word])\n\ndef correction(word): \n    \"Most probable spelling correction for word.\"\n    return max(candidates_norvig(word), key=P)\n\ndef correct_sentence_norvig(sentence):\n    return ' '.join(correction(word) for word in sentence.split())","metadata":{"id":"OwZWaX9VVs7B","trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:29:18.433338Z","iopub.execute_input":"2025-02-26T05:29:18.433763Z","iopub.status.idle":"2025-02-26T05:29:18.976910Z","shell.execute_reply.started":"2025-02-26T05:29:18.433730Z","shell.execute_reply":"2025-02-26T05:29:18.976094Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import re\nimport random\nfrom collections import defaultdict, Counter\n\n###############################\n# Evaluation Code\n###############################\n\ndef introduce_noise(word, noise_prob):\n    \"\"\"Introduce a random noise operation on a word with probability noise_prob.\"\"\"\n    if random.random() < noise_prob:\n        op = random.choice(['delete', 'insert', 'substitute', 'transpose'])\n        if op == 'delete' and len(word) > 1:\n            pos = random.randrange(len(word))\n            return word[:pos] + word[pos+1:]\n        elif op == 'insert':\n            pos = random.randrange(len(word)+1)\n            letter = random.choice('abcdefghijklmnopqrstuvwxyz')\n            return word[:pos] + letter + word[pos:]\n        elif op == 'substitute':\n            pos = random.randrange(len(word))\n            letter = random.choice('abcdefghijklmnopqrstuvwxyz')\n            while letter == word[pos]:\n                letter = random.choice('abcdefghijklmnopqrstuvwxyz')\n            return word[:pos] + letter + word[pos+1:]\n        elif op == 'transpose' and len(word) > 1:\n            pos = random.randrange(len(word)-1)\n            return word[:pos] + word[pos+1] + word[pos] + word[pos+2:]\n    return word\n\ndef add_noise_to_sentence(sentence, noise_prob):\n    \"\"\"Apply noise to each word in the sentence.\"\"\"\n    return ' '.join(introduce_noise(word, noise_prob) for word in sentence.split())\n\ndef evaluate(corrector_func, test_set, noise_prob):\n    \"\"\"\n    Evaluate a given corrector function on a test set.\n    Returns the overall word-level accuracy.\n    \"\"\"\n    total_words = 0\n    correct_words = 0\n    for original in test_set:\n        noisy = add_noise_to_sentence(original, noise_prob)\n        corrected = corrector_func(noisy)\n        # Normalize and split into words.\n        original_words = original.lower().split()\n        corrected_words = corrected.lower().split()\n        for ow, cw in zip(original_words, corrected_words):\n            total_words += 1\n            if ow == cw:\n                correct_words += 1\n    return correct_words / total_words if total_words > 0 else 0\n\n# Example Test Set: You can expand this list for more comprehensive evaluation.\ntest_set = [\n    \"This is a test sentence for evaluation.\",\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"I am a student in the university.\",\n    \"This is a good example of a context-sensitive corrector.\",\n    \"Our solution should outperform Norvig's corrector on noisy input.\",\n    \"She sells seashells by the seashore.\",\n    \"A journey of a thousand miles begins with a single step.\",\n    \"To be or not to be, that is the question.\",\n    \"All that glitters is not gold.\",\n    \"The pen is mightier than the sword.\",\n    \"An apple a day keeps the doctor away.\",\n    \"Better late than never.\",\n    \"Actions speak louder than words.\",\n    \"Practice makes perfect.\",\n    \"When in Rome, do as the Romans do.\",\n    \"The early bird catches the worm.\",\n    \"A picture is worth a thousand words.\",\n    \"Beauty is in the eye of the beholder.\",\n    \"Necessity is the mother of invention.\",\n    \"Honesty is the best policy.\"\n]\n\n# Noise probability can be adjusted (e.g., 0.2, 0.3, 0.5)\nnoise_probability = 0.3\n\n# Evaluate our corrector (context-sensitive)\nour_accuracy = evaluate(lambda s: process_line(s, model), test_set, noise_probability)\n# Evaluate Norvig's corrector (context-insensitive)\nnorvig_accuracy = evaluate(correct_sentence_norvig, test_set, noise_probability)\n\nprint(f\"Noise Probability: {noise_probability*100:.0f}%\")\nprint(f\"Accuracy of our corrector: {our_accuracy*100:.2f}%\")\nprint(f\"Accuracy of Norvig's corrector: {norvig_accuracy*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:29:22.142158Z","iopub.execute_input":"2025-02-26T05:29:22.142539Z","iopub.status.idle":"2025-02-26T05:29:26.647172Z","shell.execute_reply.started":"2025-02-26T05:29:22.142504Z","shell.execute_reply":"2025-02-26T05:29:26.645902Z"}},"outputs":[{"name":"stdout","text":"Noise Probability: 30%\nAccuracy of our corrector: 73.05%\nAccuracy of Norvig's corrector: 70.92%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"We expect the accuracy of our corrector to be better in real case scenarios, because here we did a completly random noise, and we will not get the benefite of the keyboard adjacent as it happen only in real cases when the user write on the keybord","metadata":{}},{"cell_type":"markdown","source":"#### Useful resources (also included in the archive in moodle):\n\n1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}